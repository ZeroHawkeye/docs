---
title: '爬取'
description: 'Firecrawl可以递归搜索URL的子域名，并收集内容'
icon: 'spider'
og:title: "爬取 | Firecrawl"
og:description: "Firecrawl可以递归搜索URL的子域名，并收集内容"
---

import InstallationPython from "/snippets/v1/installation/python.mdx";
import InstallationNode from "/snippets/v1/installation/js.mdx";
import InstallationGo from "/snippets/v1/installation/go.mdx";
import InstallationRust from "/snippets/v1/installation/rust.mdx";
import CrawlPython from "/snippets/v1/crawl/base/python.mdx";
import CrawlNode from "/snippets/v1/crawl/base/js.mdx";
import CrawlGo from "/snippets/v1/crawl/base/go.mdx";
import CrawlRust from "/snippets/v1/crawl/base/rust.mdx";
import CrawlCURL from "/snippets/v1/crawl/base/curl.mdx";
import AsyncCrawlOutput from "/snippets/v1/crawl-async/base/output.mdx";
import CheckCrawlJobPython from "/snippets/v1/crawl-status/short/python.mdx";
import CheckCrawlJobNode from "/snippets/v1/crawl-status/short/js.mdx";
import CheckCrawlJobGo from "/snippets/v1/crawl-status/short/go.mdx";
import CheckCrawlJobRust from "/snippets/v1/crawl-status/short/rust.mdx";
import CheckCrawlJobCURL from "/snippets/v1/crawl-status/short/curl.mdx";
import CheckCrawlJobOutputScraping from "/snippets/v1/crawl-status/base/output-scraping.mdx";
import CheckCrawlJobOutputCompleted from "/snippets/v1/crawl-status/base/output-completed.mdx";
import CrawlWebSocketPython from "/snippets/v1/crawl-websocket/base/python.mdx";
import CrawlWebSocketNode from "/snippets/v1/crawl-websocket/base/js.mdx";
import CrawlWebhookCURL from "/snippets/v1/crawl-webhook/base/curl.mdx";

Firecrawl彻底爬取网站，确保全面的数据提取，同时绕过任何网络拦截机制。以下是其工作原理：

1. **URL分析：**
   从指定的URL开始，通过查看网站地图来识别链接，然后爬取网站。如果找不到网站地图，它将跟随链接爬取网站。

2. **递归遍历：**
   递归跟踪每个链接以发现所有子页面。

3. **内容抓取：**
   从每个访问的页面收集内容，同时处理JavaScript渲染或速率限制等复杂问题。

4. **结果编译：**
   将收集的数据转换为干净的markdown或结构化输出，非常适合LLM处理或任何其他任务。

这种方法保证了从任何起始URL进行彻底的爬取和数据收集。


## 爬取


### /crawl 端点

用于爬取URL及其所有可访问的子页面。这会提交一个爬取任务并返回一个任务ID，用于检查爬取状态。


<Warning>默认情况下 - 如果页面的子链接不是您提供的URL的子链接，爬取将忽略这些子链接。因此，如果您爬取website.com/blogs/，则不会返回website.com/other-parent/blog-1。如果您想要website.com/other-parent/blog-1，请使用`allowBackwardLinks`参数</Warning>


### 安装 

<CodeGroup>

<InstallationPython />
<InstallationNode />
<InstallationGo />
<InstallationRust />

</CodeGroup>

### 使用方法

<CodeGroup>

<CrawlPython />
<CrawlNode />
<CrawlGo />
<CrawlRust />
<CrawlCURL />

</CodeGroup>

### 响应

如果您使用cURL或SDK上的`async crawl`函数，这将返回一个`ID`，您可以使用它来检查爬取状态。

<AsyncCrawlOutput />

### 检查爬取任务

用于检查爬取任务的状态并获取其结果。

<Note>此端点仅适用于正在进行中或最近完成的爬取。</Note>


<CodeGroup>

<CheckCrawlJobPython />
<CheckCrawlJobNode />
<CheckCrawlJobGo />
<CheckCrawlJobRust />
<CheckCrawlJobCURL />

</CodeGroup>

#### 响应处理

响应根据爬取状态而变化。

对于未完成或超过10MB的大型响应，会提供一个`next`URL参数。您必须请求此URL以检索下一个10MB的数据。如果`next`参数不存在，则表示爬取数据的结束。

skip参数设置每个返回结果块的最大结果数。

<Info>
skip和next参数仅在直接访问API时相关。如果您使用SDK，我们会为您处理这些参数，并一次性返回所有结果。
</Info>


<CodeGroup>
  <CheckCrawlJobOutputScraping />
  <CheckCrawlJobOutputCompleted />
</CodeGroup>

## 爬取WebSocket

Firecrawl基于WebSocket的方法`爬取URL并监视`，实现了实时数据提取和监控。使用URL启动爬取，并通过页面限制、允许的域名和输出格式等选项自定义它，非常适合即时数据处理需求。

<CodeGroup>
  <CrawlWebSocketPython />
  <CrawlWebSocketNode />
</CodeGroup>

## 爬取Webhook

您现在可以向`/crawl`端点传递一个`webhook`参数。当爬取开始、更新和完成时，这将向您指定的URL发送POST请求。

webhook现在会为每个爬取的页面触发，而不仅仅是在最后返回整个结果。

<CrawlWebhookCURL />

### Webhook事件

现在有4种类型的事件：

- `crawl.started` - 当爬取开始时触发。
- `crawl.page` - 为每个爬取的页面触发。
- `crawl.completed` - 当爬取完成时触发，让您知道它已完成（测试版）**
- `crawl.failed` - 当爬取失败时触发。

### Webhook响应

- `success` - 如果webhook成功正确爬取页面。
- `type` - 发生的事件类型。
- `id` - 爬取的ID。
- `data` - 抓取的数据（数组）。这只会在`crawl.page`上非空，如果页面成功抓取，将包含1个项目。响应与`/scrape`端点相同。
- `error` - 如果webhook失败，这将包含错误消息。

**测试版考虑因素

- 有极小的可能性`crawl.completed`事件可能在最终的`crawl.page`事件仍在处理时触发。我们正在修复这个问题。

