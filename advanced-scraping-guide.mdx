---
title: "高级抓取指南"
description: "学习如何使用高级选项改进您的Firecrawl抓取。"
og:title: "高级抓取指南 | Firecrawl"
og:description: "学习如何使用高级选项改进您的Firecrawl抓取。"
---

本指南将带您了解Firecrawl的不同端点以及如何充分利用所有参数。

## 使用Firecrawl进行基本抓取 (/scrape)

要抓取单个页面并获取干净的markdown内容，您可以使用`/scrape`端点。

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR_API_KEY")

content = app.scrape_url("https://docs.firecrawl.dev")
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { FirecrawlApp } from 'firecrawl-js';

const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

const content = await app.scrapeUrl('https://docs.firecrawl.dev');
```

```go Go
// go get github.com/mendableai/firecrawl-go

import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
    log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
  }

  content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
  if err != nil {
    log.Fatalf("Failed)
  }
}
```

```rust Rust
// 使用 Cargo 安装 firecrawl_rs crate

use firecrawl_rs::FirecrawlApp;
#[tokio::main]
async fn main() {
  // Initialize the FirecrawlApp with the API key
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
    Err(e) => eprintln!("Scrape failed: {}", e),
  }
}
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

## 抓取PDF文件

**Firecrawl默认支持抓取PDF文件。** 您可以使用`/scrape`端点抓取PDF链接并获取PDF的文本内容。您可以通过设置`parsePDF`为`false`来禁用此功能。

## 抓取选项

使用`/scrape`端点时，您可以通过多个参数自定义抓取行为。以下是可用选项：

### 使用`formats`设置响应中的内容格式

- **类型**: `array`
- **枚举值**: `["markdown", "links", "html", "rawHtml", "screenshot"]`
- **描述**: 指定要包含在响应中的格式。选项包括：
  - `markdown`: 以Markdown格式返回抓取的内容。
  - `links`: 包含页面上找到的所有超链接。
  - `html`: 以HTML格式提供内容。
  - `rawHtml`: 提供原始HTML内容，不进行任何处理。
  - `screenshot`: 包含页面在浏览器中显示的截图。
  - `extract`: 使用LLM从页面提取结构化信息。
- **默认值**: `["markdown"]`

### 使用`onlyMainContent`获取完整页面内容作为markdown

- **类型**: `boolean`
- **描述**: 默认情况下，抓取器只会返回页面的主要内容，不包括页眉、导航栏、页脚等。将此设置为`false`以返回完整页面内容。
- **默认值**: `true`

### 使用`includeTags`设置要包含的标签

- **类型**: `array`
- **描述**: 指定要包含在响应中的HTML标签、类和ID。
- **默认值**: undefined

### 使用`excludeTags`设置要排除的标签

- **类型**: `array`
- **描述**: 指定要从响应中排除的HTML标签、类和ID。
- **默认值**: undefined

### 使用`waitFor`等待页面加载

- **类型**: `integer`
- **描述**: 仅作为最后手段使用。等待指定的毫秒数让页面加载，然后再获取内容。
- **默认值**: `0`

### 设置最大`timeout`

- **类型**: `integer`
- **描述**: 设置抓取器等待页面响应的最大持续时间（毫秒），超过此时间将中止操作。
- **默认值**: `30000`（30秒）

### 使用示例

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization : Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": ["markdown", "links", "html", "rawHtml", "screenshot"],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000
    }'
```

在此示例中，抓取器将：

- 以markdown格式返回完整页面内容。
- 在响应中包含markdown、原始HTML、HTML、链接和截图。
- 响应将仅包含HTML标签`<h1>`、`<p>`、`<a>`和具有类`.main-content`的元素，同时排除具有ID`#ad`和`#footer`的任何元素。
- 等待1000毫秒（1秒）让页面加载，然后再获取内容。
- 将抓取请求的最大持续时间设置为15000毫秒（15秒）。

这是API参考：[Scrape端点文档](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

## 提取器选项

使用`/scrape`端点时，您可以使用`extract`参数指定从页面内容提取结构化信息的选项。以下是可用选项：

### 使用LLM提取

### schema

- **类型**: `object`
- **必需**: 如果提供了prompt则为False
- **描述**: 要提取的数据的模式。这定义了提取数据的结构。

### system prompt

- **类型**: `string`
- **必需**: False
- **描述**: LLM的系统提示。

### prompt

- **类型**: `string`
- **必需**: 如果提供了schema则为False
- **描述**: 用于LLM以正确结构提取数据的提示。
- **示例**: `"Extract the features of the product"`


### 使用示例

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "formats": ["markdown", "extract"],
      "extract": {
        "prompt": "Extract the features of the product"
      }
    }'
```

```json
{
  "success": true,
  "data": {
    "content": "Raw Content",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "robots": "follow, index",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "ogUrl": "https://docs.firecrawl.dev/",
      "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://docs.firecrawl.dev/",
      "statusCode": 200
    },
    "extract": {
      "product": "Firecrawl",
      "features": {
        "general": {
          "description": "Turn websites into LLM-ready data.",
          "openSource": true,
          "freeCredits": 500,
          "useCases": [
            "AI applications",
            "Data science",
            "Market research",
            "Content aggregation"
          ]
        },
        "crawlingAndScraping": {
          "crawlAllAccessiblePages": true,
          "noSitemapRequired": true,
          "dynamicContentHandling": true,
          "dataCleanliness": {
            "process": "Advanced algorithms",
            "outputFormat": "Markdown"
          }
        },
        ...
      }
    }
  }
}
```

## 操作

使用`/scrape`端点时，Firecrawl允许您在抓取内容之前对网页执行各种操作。这对于与动态内容交互、浏览页面或访问需要用户交互的内容特别有用。

### 可用操作

#### wait

- **类型**: `object`
- **描述**: 等待指定的毫秒数。
- **属性**:
  - `type`: `"wait"`
  - `milliseconds`: 等待的毫秒数。
- **示例**:
  ```json
  {
    "type": "wait",
    "milliseconds": 2000
  }
  ```

#### screenshot

- **类型**: `object`
- **描述**: 截取屏幕截图。
- **属性**:
  - `type`: `"screenshot"`
  - `fullPage`: 截图是否应为全页面或视口大小？（默认：`false`）
- **示例**:
  ```json
  {
    "type": "screenshot",
    "fullPage": true
  }
  ```

#### click

- **类型**: `object`
- **描述**: 点击元素。
- **属性**:
  - `type`: `"click"`
  - `selector`: 用于查找元素的查询选择器。
- **示例**:
  ```json
  {
    "type": "click",
    "selector": "#load-more-button"
  }
  ```

#### write

- **类型**: `object`
- **描述**: 在输入字段中写入文本。
- **属性**:
  - `type`: `"write"`
  - `text`: 要输入的文本。
  - `selector`: 输入字段的查询选择器。
- **示例**:
  ```json
  {
    "type": "write",
    "text": "Hello, world!",
    "selector": "#search-input"
  }
  ```

#### press

- **类型**: `object`
- **描述**: 在页面上按下键。
- **属性**:
  - `type`: `"press"`
  - `key`: 要按下的键。
- **示例**:
  ```json
  {
    "type": "press",
    "key": "Enter"
  }
  ```

#### scroll

- **类型**: `object`
- **描述**: 滚动页面。
- **属性**:
  - `type`: `"scroll"`
  - `direction`: 滚动方向（`"up"`或`"down"`）。
  - `amount`: 滚动的像素数。
- **示例**:
  ```json
  {
    "type": "scroll",
    "direction": "down",
    "amount": 500
  }
  ```

有关操作参数的更多详细信息，请参阅[API参考](https://docs.firecrawl.dev/api-reference/endpoint/scrape)。


## 抓取多个页面

要抓取多个页面，您可以使用`/crawl`端点。此端点允许您指定要抓取的基本URL，所有可访问的子页面都将被抓取。

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

返回一个id

```json
{ "id": "1234-5678-9101" }
```

### 检查抓取任务

用于检查抓取任务的状态并获取其结果。

```bash
curl -X GET https://api.firecrawl.dev/v1/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
```

#### 分页/下一个URL

如果内容大于10MB或抓取任务仍在运行，响应将包含一个`next`参数。此参数是指向结果下一页的URL。您可以使用此参数获取结果的下一页。

### 爬虫选项

使用`/crawl`端点时，您可以通过请求体参数自定义爬取行为。以下是可用选项：

#### `includePaths`

- **类型**: `array`
- **描述**: 要包含在爬取中的URL模式。只有匹配这些模式的URL才会被爬取。
- **示例**: `["/blog/*", "/products/*"]`

#### `excludePaths`

- **类型**: `array`
- **描述**: 要从爬取中排除的URL模式。匹配这些模式的URL将被跳过。
- **示例**: `["/admin/*", "/login/*"]`

#### `maxDepth`

- **类型**: `integer`
- **描述**: 相对于输入URL的最大爬取深度。maxDepth为0只抓取输入的URL。maxDepth为1抓取输入的URL和所有一级深度的页面。maxDepth为2抓取输入的URL和所有深度最多为两级的页面。更高的值遵循相同的模式。
- **示例**: `2`

#### `limit`

- **Type**: `integer`
- **Description**: The maximum number of pages to crawl.
- **Default Value**: `10000`

#### `allowBackwardLinks`

- **类型**: `boolean`
- **描述**: 此选项允许爬虫导航到目录结构中比基本URL更高的URL。例如，如果基本URL是`example.com/blog/topic`，启用此选项允许爬取到像`example.com/blog`或`example.com`这样的页面，这些页面在路径层次结构中相对于基本URL是向后的。
- **默认值**: `false`

### `allowExternalLinks`

- **类型**: `boolean`
- **描述**: 此选项允许爬虫跟随指向外部域的链接。使用此选项时要小心，因为它可能导致爬取仅基于`limit`和`maxDepth`值停止。
- **默认值**: `false`

#### scrapeOptions

作为爬虫选项的一部分，您还可以指定`scrapeOptions`参数。此参数允许您自定义每个页面的抓取行为。

- **类型**: `object`
- **描述**: 抓取器的选项。
- **示例**: `{"formats": ["markdown", "links", "html", "rawHtml", "screenshot"], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **默认值**: `{ "formats": ["markdown"] }`
- **参见**: [抓取选项](#使用formats设置响应中的内容格式)

### 使用示例

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization : Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["/blog/*", "/products/*"],
      "excludePaths": ["/admin/*", "/login/*"],
      "maxDepth": 2,
      "limit": 1000
    }'
```

在此示例中，爬虫将：

- 只爬取匹配模式`/blog/*`和`/products/*`的URL。
- 跳过匹配模式`/admin/*`和`/login/*`的URL。
- 返回每个页面的完整文档数据。
- 爬取最大深度为2。
- 爬取最多1000个页面。

## 使用`/map`映射网站链接

`/map`端点擅长识别与给定网站上下文相关的URL。此功能对于理解网站的上下文链接环境至关重要，这可以极大地帮助战略性网站分析和导航规划。

### 使用方法

要使用`/map`端点，您需要发送一个GET请求，其中包含要映射的页面的URL。以下是使用`curl`的示例：

```bash
curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

这将返回一个包含与url上下文相关的链接的JSON对象。

### 示例响应

```json
  {
    "success":true,
    "links":[
      "https://docs.firecrawl.dev",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-get",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-post",
      "https://docs.firecrawl.dev/api-reference/endpoint/map",
      "https://docs.firecrawl.dev/api-reference/endpoint/scrape",
      "https://docs.firecrawl.dev/api-reference/introduction",
      "https://docs.firecrawl.dev/articles/search-announcement",
      ...
    ]
  }
```

### 映射选项

#### `search`

- **类型**: `string`
- **描述**: 搜索包含特定文本的链接。
- **示例**: `"blog"`

#### `limit`

- **类型**: `integer`
- **描述**: 返回的最大链接数。
- **默认值**: `100`

#### `ignoreSitemap`

- **类型**: `boolean`
- **描述**: 爬取时忽略网站站点地图
- **默认值**: `true`

#### `includeSubdomains`

- **类型**: `boolean`
- **描述**: 包含网站的子域
- **默认值**: `false`

这是API参考：[Map端点文档](https://docs.firecrawl.dev/api-reference/endpoint/map)

