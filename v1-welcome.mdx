---
title: 欢迎使用 V1
description: "Firecrawl 允许您将整个网站转换为 LLM 可用的 markdown"
og:title: "欢迎使用 V1 | Firecrawl"
og:description: "Firecrawl 允许您将整个网站转换为 LLM 可用的 markdown"
---

import InstallationPython from "/snippets/v1/installation/python.mdx";
import InstallationNode from "/snippets/v1/installation/js.mdx";
import InstallationGo from "/snippets/v1/installation/go.mdx";
import InstallationRust from "/snippets/v1/installation/rust.mdx";
import ScrapePython from "/snippets/v1/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v1/scrape/base/js.mdx";
import ScrapeGo from "/snippets/v1/scrape/base/go.mdx";
import ScrapeRust from "/snippets/v1/scrape/base/rust.mdx";
import ScrapeCURL from "/snippets/v1/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v1/scrape/base/output.mdx";
import MapPython from "/snippets/v1/map/base/python.mdx";
import MapJavaScript from "/snippets/v1/map/base/js.mdx";
import MapGo from "/snippets/v1/map/base/go.mdx";
import MapRust from "/snippets/v1/map/base/rust.mdx";
import MapCURL from "/snippets/v1/map/base/curl.mdx";
import MapResponse from "/snippets/v1/map/base/output.mdx";
import CrawlWebSocketPythonBase from "/snippets/v1/crawl-websocket/base/python.mdx";
import CrawlWebSocketNodeBase from "/snippets/v1/crawl-websocket/base/js.mdx";
import ExtractCURL from "/snippets/v1/llm-extract/base/curl.mdx";
import ExtractPython from "/snippets/v1/llm-extract/base/python.mdx";
import ExtractNode from "/snippets/v1/llm-extract/base/js.mdx";
import ExtractOutput from "/snippets/v1/llm-extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/v1/llm-extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/v1/llm-extract/no-schema/output.mdx";
import CrawlWebhookCURL from "/snippets/v1/crawl-webhook/base/curl.mdx";


Firecrawl V1 已经到来！我们推出了更可靠、更开发者友好的 API。

以下是新功能：

- `/scrape` 的输出格式。选择您想要的输出格式。
- 新的 [`/map` 端点](/features/map)，用于获取网页的大部分 URL。
- 开发者友好的 `/crawl/{id}` 状态 API。
- 所有计划的速率限制提高 2 倍。
- [Go SDK](/sdks/go) 和 [Rust SDK](/sdks/rust)
- 团队支持
- 仪表板中的 API 密钥管理。
- `onlyMainContent` 现在默认为 `true`。
- `/crawl` webhook 和 websocket 支持。


## 抓取格式

您现在可以选择想要的输出格式。您可以指定多种输出格式。支持的格式有：

- Markdown (markdown)
- HTML (html)
- 原始 HTML (rawHtml)（无修改）
- 截图 (screenshot 或 screenshot@fullPage)
- 链接 (links)

输出键将与您选择的格式匹配。

<CodeGroup>

  <ScrapePython />

  <ScrapeNode />

  <ScrapeGo />

  <ScrapeRust />

  <ScrapeCURL />

</CodeGroup>

### 响应

SDK 将直接返回数据对象。cURL 将返回如下所示的完整负载。

<ScrapeResponse />

## 介绍 /map（Alpha 版）

从单个 URL 到整个网站地图的最简单方法。

### 用法

<CodeGroup>

<MapPython />
<MapJavaScript />
<MapGo />
<MapRust />
<MapCURL />

</CodeGroup>

### 响应

SDK 将直接返回数据对象。cURL 将返回如下所示的完整负载。

<MapResponse />

## WebSockets

要使用 WebSockets 爬取网站，请使用 `Crawl URL and Watch` 方法。

<CodeGroup>

<CrawlWebSocketPythonBase />
<CrawlWebSocketNodeBase />

</CodeGroup>

## 提取格式

LLM 提取现在在 v1 中以 `extract` 格式提供。要从页面提取结构化数据，您可以向端点传递模式或仅提供提示。

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

输出：

<ExtractOutput />

### 无模式提取（新功能）

您现在可以通过仅向端点传递 `prompt` 来进行无模式提取。LLM 会选择数据的结构。

<CodeGroup>

<ExtractNoSchemaCURL />

</CodeGroup>

输出：

<ExtractNoSchemaOutput />

## 新的爬取 Webhook

您现在可以向 `/crawl` 端点传递 `webhook` 参数。这将在爬取开始、更新和完成时向您指定的 URL 发送 POST 请求。

webhook 现在会为每个爬取的页面触发，而不仅仅是在最后提供整个结果。

<CrawlWebhookCURL />

### Webhook 事件

现在有 4 种类型的事件：

- `crawl.started` - 爬取开始时触发。
- `crawl.page` - 为每个爬取的页面触发。
- `crawl.completed` - 爬取完成时触发，让您知道它已完成。
- `crawl.failed` - 爬取失败时触发。

### Webhook 响应

- `success` - 如果 webhook 成功正确爬取页面。
- `type` - 发生的事件类型。
- `id` - 爬取的 ID。
- `data` - 抓取的数据（数组）。这只会在 `crawl.page` 上非空，如果页面成功抓取，将包含 1 个项目。响应与 `/scrape` 端点相同。
- `error` - 如果 webhook 失败，这将包含错误消息。

## 从 V0 迁移

## /scrape 端点

更新后的 `/scrape` 端点经过重新设计，提高了可靠性和易用性。新的 `/scrape` 请求体结构如下：

```json
{
  "url": "<string>",
  "formats": ["markdown", "html", "rawHtml", "links", "screenshot"],
  "includeTags": ["<string>"],
  "excludeTags": ["<string>"],
  "headers": { "<key>": "<value>" },
  "waitFor": 123,
  "timeout": 123
}
```

### 格式

您现在可以选择想要的输出格式。您可以指定多种输出格式。支持的格式有：

- Markdown (markdown)
- HTML (html)
- 原始 HTML (rawHtml)（无修改）
- 截图 (screenshot 或 screenshot@fullPage)
- 链接 (links)

默认情况下，输出将仅包含 markdown 格式。

### 新请求体的详细信息

下表概述了 V1 中 `/scrape` 端点请求体参数的变化。

| 参数 | 变化 | 描述 |
| --------- | ------ | ----------- |
| `onlyIncludeTags` | 移动并重命名 | 移至根级别。并重命名为 `includeTags`。 |
| `removeTags` | 移动并重命名 | 移至根级别。并重命名为 `excludeTags`。 |
| `onlyMainContent`| 移动 | 移至根级别。默认为 `true`。 |
| `waitFor`| 移动 | 移至根级别。 |
| `headers`| 移动 | 移至根级别。 |
| `parsePDF`| 移动 | 移至根级别。 |
| `extractorOptions`| 无变化 ||
| `timeout`| 无变化 ||
| `pageOptions` | 移除 | 不再需要 `pageOptions` 参数。抓取选项已移至根级别。 |
| `replaceAllPathsWithAbsolutePaths` | 移除 | 不再需要 `replaceAllPathsWithAbsolutePaths`。现在每个路径默认为绝对路径。 |
| `includeHtml`| 移除 | 改为在 `formats` 中添加 `"html"`。 |
| `includeRawHtml`| 移除 | 改为在 `formats` 中添加 `"rawHtml"`。 |
| `screenshot`| 移除 | 改为在 `formats` 中添加 `"screenshot"`。 |
| `fullPageScreenshot`| 移除 | 改为在 `formats` 中添加 `"screenshot@fullPage"`。 |
| `extractorOptions` | 移除 | 改用带有 `extract` 对象的 `"extract"` 格式。 |

新的 `extract` 格式在 [llm-extract](/features/extract) 部分中描述。

## /crawl 端点

我们还更新了 `v1` 上的 `/crawl` 端点。查看下面改进的请求体：

```json
{
  "url": "<string>",
  "excludePaths": ["<string>"],
  "includePaths": ["<string>"],
  "maxDepth": 2,
  "ignoreSitemap": true,
  "limit": 10,
  "allowBackwardLinks": true,
  "allowExternalLinks": true,
  "scrapeOptions": {
    // 与 /scrape 中相同的选项
    "formats": ["markdown", "html", "rawHtml", "screenshot", "links"],
    "headers": { "<key>": "<value>" },
    "includeTags": ["<string>"],
    "excludeTags": ["<string>"],
    "onlyMainContent": true,
    "waitFor": 123
  }
}
```


### 新请求体的详细信息

下表概述了 V1 中 `/crawl` 端点请求体参数的变化。

| 参数 | 变化 | 描述 |
| --------- | ------ | ----------- |
| `pageOptions` | 重命名 | 重命名为 `scrapeOptions`。 |
| `includes` | 移动并重命名 | 移至根级别。重命名为 `includePaths`。 |
| `excludes` | 移动并重命名 | 移至根级别。重命名为 `excludePaths`。 |
| `allowBackwardCrawling` | 移动并重命名 | 移至根级别。重命名为 `allowBackwardLinks`。 |
| `allowExternalLinks` | 移动 | 移至根级别。 |
| `maxDepth` | 移动 | 移至根级别。 |
| `ignoreSitemap` | 移动 | 移至根级别。 |
| `limit` | 移动 | 移至根级别。 |
| `crawlerOptions` | 移除 | 不再需要 `crawlerOptions` 参数。爬取选项已移至根级别。 |
| `timeout` | 移除 | 改用 `scrapeOptions` 中的 `timeout`。 |